---
title: "DATS610 Final Project- Analyzing trends in U.S. Traffic Accident Data"
author: "Junran Cao, Jordan Dawes, and Carter Rogers"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=F}
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)  
library(corrplot)
library(ezids)
library(httr)
library(randomForest)
library(tree)
library(caret)
library(broom)
```


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times

dataset <- read.csv("~/Downloads/US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset) #335,552 observations remaining

#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)

#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))
```

# Background
## Overview

The topic we have chosen to examine in this project is traffic accidents in the United States. According to the National Highway and Transportation Security Agency, over 30,000 fatal car accidents occurred in 2019 alone. The United States is a nation that relies heavily on automobile traffic in order to transport people from point A to point B. Car accidents are an unfortunate reality of our modern transportation infrastructure. The severity of these accidents can range from minor fender-benders to deadly collisions. Our goal for this project is to study the makeup of these accidents to gain potential insights from the data available to us. 

## Prior Research



## Dataset Description
 
The original data set from Kaggle contains over 1.5 million observations; unfortunately, the majority of these observations contain missing values that we will remove from our analysis. After removing rows with missing values, removing unnecessary columns, and encoding variables as the proper type, we obtain a data set of 335,552 observations structured as follows:

```{r}
str(dataset)
```

Some of these variables might be useful, but fall outside the scope of this project. For example, the 'Description' column contains intriguing information but requires some language processing implementation to parse the relevant information from this column. We also have a bevy of geographic information from where the accidents occurred available to us, but including these features into our analysis would greatly complicate the modeling and testing processes. The key response variables we can use in our analysis are 'Severity' and 'Distance.mi.' which indicate the severity of a given accident on a scale of 1-4, and the distance that traffic was backed up as a result of the accident.
 
## Limitations of the dataset

There are several limitations of the data set that will complicate our analysis of the data. One nice feature of the data set is that we have access to both a categorical and numeric response variable, opening up a wide range of modeling techniques at our disposal. Unfortunately, both of these variables are imperfect to use as response variables. The severity of an accident is somewhat subjective; the description of the data set on Kaggle does not include the criteria for the classification of the severity of an accident other than the fact that severity is ascending from least severe (1) to most severe (4). For the purposes of this project, we will assume that accidents with lower severity are minor crashes with minimal damages to the vehicles and little to no injuries to the passengers, while more severe accidents are defined by greater damages to the vehicle and/or more severe injuries to the passengers. The distance that traffic is impacted as a result of an accident is difficult to record, so we will need to inspect the data to see if any outliers are present.

## SMART Questions and Hypotheses

1. Can we classify the severity of a given accident based on temperature, wind speed, or other weather conditions present during the accident?

From prior knowledge we can infer that poor weather conditions lead to more severe traffic accidents. Low temperatures and high wind speeds can cause poor conditions that make driving very difficult. 

2. What factors best predict the severity of an accident?

We are curious to see which factors present during an accident best predict the severity of the ensuing accident. We plan to utilize as many variables as possible in the data set to compare their potential relationships with the severity of an accident.

3. Is there a relationship between civil twilight and accident occurrences? Is there any relationship between visibility and the severity of an accident?



4. Is there any relationship between the severity of an accident and the road conditions (traffic stops, railways, junctions, etc.)?



# Analysis 
## Exploratory Data Analysis (EDA)

```{r}
table(dataset$Severity)
```

In order to use the 'Severity' column as a response variable in our modeling, we first need to examine the distribution of severity across the four levels. As seen in the table above, the vast majority of accidents in the data are recorded as severity '2'. We can assume that accidents of severity '2' are more severe than a negligible fender-bender, but not severe enough to cause major damage or severe injury to the passengers involved. This makes sense intuitively because accidents with severity '1' might not be noteworthy enough to be recorded by law enforcement agencies, while crashes with greater severity are far less common. We will need to keep this imbalanced distribution of 'Severity' in mind during the modeling process.

```{r}
ggplot(data = dataset, aes(x = Temperature.F., y = Wind_Speed.mph., colour = Severity)) + geom_point() + scale_y_continuous(limits = c(0, 50))
```

We are curious to see how severity is impacted by conditions present at the time of the accident. One of our goals for this project is to be able to classify the severity of an accident using temperature, wind speed, and other weather conditions as predictors. We can't see any definitive groups of observations by level of severity, but we will attempt to classify these accidents with minimal error.  

## Tests and Modeling

### Can we classify the severity of a given accident based on temperature, wind speed, or other weather conditions present during the accident?

We will build a Random Forest classification model to classify the severity of an accident using the following predictor variables: Temperature, Wind Speed (mph), Wind Chill (F), Humidity, Pressure (in), Visibility, and Precipitation (in). Random Forests is a useful algorithm to base our modeling process on because it handles many predictor variables better than other classifiers. Because the Random Forest algorithm only uses a small subset of features to build each decision tree off of, the model performs well despite the inclusion of collinear features or features that dominate the decision-making process at each node. Random Forest is an appealing model to use because we are using several predictor variables that are correlated with each other, so we won't have to undergo a lengthy factor selection process here.

```{r}
set.seed(123)

newdata2 <- subset(dataset, select = c(Severity, Temperature.F., Wind_Speed.mph., Wind_Chill.F., Humidity..., Pressure.in., vis, Precipitation.in.))

#scale vars
scaleddata2 <- as.data.frame(scale(newdata2[2:8], center = TRUE, scale = TRUE))
scaleddata2 <- cbind(newdata2[,1], scaleddata2)
names(scaleddata2)[1] <- 'Severity'

trainIndex2 <- createDataPartition(scaleddata2$Severity, p = .7, list = FALSE, times = 1)
carter_train2 <- scaleddata2[trainIndex2,]
carter_test2 <- scaleddata2[-trainIndex2,]

rf_model2 <- randomForest(Severity ~ .
                    , data = carter_train2
                    , mtry = 3
                    , ntree = 20
                    , importance = TRUE
                    , type = "prob")
```

After normalizing the data, we can build a Random Forest model to classify accident severity based on the predictor variables that capture the weather conditions present at the time of the accident.

```{r}
predicted_table <- predict(rf_model2, carter_test2[,-1])
table(observed = carter_test2[,1], predicted = predicted_table)
print(rf_model2)
round(importance(rf_model2), 2)
```

The results of this model are generally poor due to the class imbalance of the data. Because the overwhelming majority of observations are of severity '2', the model is rewarded for naively predicting severity '2' with little regard for precision. The model resulted in a class error of $57.68\%$ for severity '1', $70.49\%$ for severity '3', and $67.23\%$ for severity '4'. Our goal now is to reduce the class error by dealing with the class imbalance of the data. One technique we can use is stratified sampling; by forcing the model to train itself using equal weights across the 4 classes of severity, we can train the model to better identify the minority classes.

```{r}
rf_model3 <- randomForest(Severity ~ .
                    , data = carter_train2
                    , mtry = 3
                    , ntree = 20
                    , importance = TRUE
                    , type = "prob"
                    , sampsize = c(1000, 1000, 1000, 1000))

predicted_table2 <- predict(rf_model3, carter_test2[,-1])
table(observed = carter_test2[,1], predicted = predicted_table2)
print(rf_model3)
round(importance(rf_model3), 2)
```

We can implement stratified sampling in our random forest modeling by specifying the parameter 'sampsize' when calling the randomForest() function. As expected, we do observe a drastic reduction in class error for severity '1', '3', and '4'. The model resulted in a class error of $38.4\%$ for severity '1', $49\%$ for severity '3', and $61.4\%$ for severity '4'. Note that the class error for severity '2' increases for the second model, but this is an expected tradeoff of de-emphasizing severity '2' in the training of the model.

### What factors best predict the severity of an accident?



### Is there a relationship between civil twilight and accident occurences? Is there any relationship between visibility and the seeverity of an accident?



### Is there any relationship between the severity of an accident and the road conditions (traffic stops, railways, junctions, etc.)?



## Findings



# Conclusion



# References


