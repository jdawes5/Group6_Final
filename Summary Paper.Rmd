---
title: "DATS610 Final Project- Analyzing trends in U.S. Traffic Accident Data"
author: "Junran Cao, Jordan Dawes, and Carter Rogers"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=F}
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)  
library(corrplot)
library(ezids)
library(httr)
library(randomForest)
library(tree)
library(caret)
library(broom)
```


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times

dataset <- read.csv("~/Downloads/US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset) #335,552 observations remaining

#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)

#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))

#Renaming relevant columns
dataset <- rename(dataset, c("civ.light" = "Civil_Twilight"),c("vis" = "Visibility.mi."))
```

# Background
## Overview

The topic we have chosen to examine in this project is traffic accidents in the United States. According to the National Highway and Transportation Security Agency, over 30,000 fatal car accidents occurred in 2019 alone. The United States is a nation that relies heavily on automobile traffic in order to transport people from point A to point B. Car accidents are an unfortunate reality of our modern transportation infrastructure. The severity of these accidents can range from minor fender-benders to deadly collisions. Our goal for this project is to study the makeup of these accidents to gain potential insights from the data available to us. 

## Prior Research

As we were doing our research in the Internet, we found that the data on traffic accidents in the U.S. were very limited. The data were either on state or country level or were not well prepared by the government agencies. We then went to Kaggle and identified a dataset that was suitable for our research purporse. The dataset we identified was well-developed and had been cited by many people. Therefore, we believed that it would serve our research purpose well. 

## Dataset Description
 
The original data set from Kaggle contains over 1.5 million observations; unfortunately, the majority of these observations contain missing values that we will remove from our analysis. After removing rows with missing values, removing unnecessary columns, and encoding variables as the proper type, we obtain a data set of 335,552 observations structured as follows:

```{r}
str(dataset)
```

Some of these variables might be useful, but fall outside the scope of this project. For example, the 'Description' column contains intriguing information but requires some language processing implementation to parse the relevant information from this column. We also have a bevy of geographic information from where the accidents occurred available to us, but including these features into our analysis would greatly complicate the modeling and testing processes. The key response variables we can use in our analysis are 'Severity' and 'Distance.mi.' which indicate the severity of a given accident on a scale of 1-4, and the distance that traffic was backed up as a result of the accident.
 
## Limitations of the dataset

There are several limitations of the data set that will complicate our analysis of the data. One nice feature of the data set is that we have access to both a categorical and numeric response variable, opening up a wide range of modeling techniques at our disposal. Unfortunately, both of these variables are imperfect to use as response variables. The severity of an accident is somewhat subjective; the description of the data set on Kaggle does not include the criteria for the classification of the severity of an accident other than the fact that severity is ascending from least severe (1) to most severe (4). For the purposes of this project, we will assume that accidents with lower severity are minor crashes with minimal damages to the vehicles and little to no injuries to the passengers, while more severe accidents are defined by greater damages to the vehicle and/or more severe injuries to the passengers. The distance that traffic is impacted as a result of an accident is difficult to record, so we will need to inspect the data to see if any outliers are present.

## SMART Questions and Hypotheses

1. Can we classify the severity of a given accident based on temperature, wind speed, or other weather conditions present during the accident?

From prior knowledge we can infer that poor weather conditions lead to more severe traffic accidents. Low temperatures and high wind speeds can cause poor conditions that make driving very difficult. 

2. What factors best predict the severity of an accident?

We are curious to see which factors present during an accident best predict the severity of the ensuing accident. We plan to utilize as many variables as possible in the data set to compare their potential relationships with the severity of an accident.

3. Is there a relationship between civil twilight and accident occurrences? Is there any relationship between visibility and the severity of an accident?

We know that if a driver is unable to see it can lead to accidents so we want to see if more accidents happen at night because this is the time of day when it may be more difficult to see. We will use Civil Twilight to define day as anytime when a driver can see without the assistance of artificial light. We also want to see if there are more sever accidents when there is less visibility in miles. 

4. Is there any relationship between the severity of an accident and the road conditions (traffic stops, railways, junctions, etc.)?



# Analysis 
## Exploratory Data Analysis (EDA)

```{r}
table(dataset$Severity)
```

In order to use the 'Severity' column as a response variable in our modeling, we first need to examine the distribution of severity across the four levels. As seen in the table above, the vast majority of accidents in the data are recorded as severity '2'. We can assume that accidents of severity '2' are more severe than a negligible fender-bender, but not severe enough to cause major damage or severe injury to the passengers involved. This makes sense intuitively because accidents with severity '1' might not be noteworthy enough to be recorded by law enforcement agencies, while crashes with greater severity are far less common. We will need to keep this imbalanced distribution of 'Severity' in mind during the modeling process.

```{r}
ggplot(data = dataset, aes(x = Temperature.F., y = Wind_Speed.mph., colour = Severity)) + geom_point() + scale_y_continuous(limits = c(0, 50))
```

```{r}
#loadPkg("dplyr")
#loadPkg("ggplot2")

visdata <- subset(dataset, civ.light != "")
visdata$civ.light <- as.factor(visdata$civ.light)

ggplot(visdata, aes(y=vis, x=civ.light, fill= Severity)) +
  geom_bar(stat='identity') +
  labs(title="Total Accidents Based on Twilight",
       x="Twilight Status",
       y="Number of Accidents",
       fill="Severity")
```


We are curious to see how severity is impacted by conditions present at the time of the accident. One of our goals for this project is to be able to classify the severity of an accident using temperature, wind speed, and other weather conditions as predictors. We can't see any definitive groups of observations by level of severity, but we will attempt to classify these accidents with minimal error.  


## Tests and Modeling

### Can we classify the severity of a given accident based on temperature, wind speed, or other weather conditions present during the accident?

We will build a Random Forest classification model to classify the severity of an accident using the following predictor variables: Temperature, Wind Speed (mph), Wind Chill (F), Humidity, Pressure (in), Visibility, and Precipitation (in). Random Forests is a useful algorithm to base our modeling process on because it handles many predictor variables better than other classifiers. Because the Random Forest algorithm only uses a small subset of features to build each decision tree off of, the model performs well despite the inclusion of collinear features or features that dominate the decision-making process at each node. Random Forest is an appealing model to use because we are using several predictor variables that are correlated with each other, so we won't have to undergo a lengthy factor selection process here.

```{r}
set.seed(123)

newdata2 <- subset(dataset, select = c(Severity, Temperature.F., Wind_Speed.mph., Wind_Chill.F., Humidity..., Pressure.in., vis, Precipitation.in.))

#scale vars
scaleddata2 <- as.data.frame(scale(newdata2[2:8], center = TRUE, scale = TRUE))
scaleddata2 <- cbind(newdata2[,1], scaleddata2)
names(scaleddata2)[1] <- 'Severity'

trainIndex2 <- createDataPartition(scaleddata2$Severity, p = .7, list = FALSE, times = 1)
carter_train2 <- scaleddata2[trainIndex2,]
carter_test2 <- scaleddata2[-trainIndex2,]

rf_model2 <- randomForest(Severity ~ .
                    , data = carter_train2
                    , mtry = 3
                    , ntree = 20
                    , importance = TRUE
                    , type = "prob")
```

After normalizing the data, we can build a Random Forest model to classify accident severity based on the predictor variables that capture the weather conditions present at the time of the accident.

```{r}
predicted_table <- predict(rf_model2, carter_test2[,-1])
table(observed = carter_test2[,1], predicted = predicted_table)
print(rf_model2)
round(importance(rf_model2), 2)
```

The results of this model are generally poor due to the class imbalance of the data. Our goal now is to reduce the class error by dealing with the class imbalance of the data. One technique we can use is stratified sampling; by forcing the model to train itself using equal weights across the 4 classes of severity, we can train the model to better identify the minority classes.

```{r}
rf_model3 <- randomForest(Severity ~ .
                    , data = carter_train2
                    , mtry = 3
                    , ntree = 20
                    , importance = TRUE
                    , type = "prob"
                    , sampsize = c(1000, 1000, 1000, 1000))

predicted_table2 <- predict(rf_model3, carter_test2[,-1])
table(observed = carter_test2[,1], predicted = predicted_table2)
print(rf_model3)
round(importance(rf_model3), 2)
```

We can implement stratified sampling in our random forest modeling by specifying the parameter 'sampsize' when calling the randomForest() function. Note that the class error for severity '2' increases for the second model, but this is an expected tradeoff of de-emphasizing severity '2' in the training of the model.

### What factors best predict the severity of an accident?

In order to determine which factors best predict the severity of an accident, we can further utilize the Random Forest method of classification. This time, we will build the model using as many of the features of the data set as possible. As mentioned earlier, Random Forest models can handle the feature selection process through generating decorrelated trees that are built off of a small subset of the variables present in the data.

```{r}
#remove all cols except numeric, factor, and binary. Also excluding Distance since this is not a "predictive" metric but rather a rough measurement of severity
rf_data = subset(dataset, select = -c(ID, Start_Time, End_Time, Distance.mi., Description, City, County, State, Zipcode, Country, Weather_Condition))

#split train-test
rf_trainIndex <- createDataPartition(rf_data$Severity, p = .7, list = FALSE, times = 1)
rf_carter_train <- rf_data[rf_trainIndex,]
rf_carter_test <- rf_data[-rf_trainIndex,]

rf_model <- randomForest(Severity ~ .
                    , data = rf_carter_train
                    , mtry = 5
                    , ntree = 20
                    , importance = TRUE
                    , type = "prob")

varImpPlot(rf_model, n.var = 5, main = "Variable Importance Plot for Random Forest Model (Severity)")
#wind direction, humidity, temperature appear in both plots
```

Using the varImpPlot() function from the 'randomForest' library, we can examine the variables that most impacted the accuracy of the model by Mean Decrease in Accuracy and Gini. The most important predictor that had the greatest impact on the model's accuracy when omitted was Atmospheric Pressure. Humidity and Wind Direction also appear in both the Mean Decrease Accuracy and Gini plots. These are the features that most impacted the Random Forest model's accuracy when omitted from the set of variables used for the decisions made by the nodes of the trees. 

### Is there a relationship between civil twilight and accident occurences? Is there any relationship between visibility and the severity of an accident?

First we want to see if there is any relationship between Severity and civil twilight as well as Severity and visibility. We can use an ANOVA test to analyze the relationship between Severity and visibility since we have categorical and numerical variables. We can use a Chi-squared test to look at the relationship between Severity and civil twilight.

```{r}
anovatest <- aov(vis ~ Severity, data = visdata)
anovatest
xkabledply(anovatest)
anovasummary<- summary(anovatest)

chitable <- table(visdata$Severity, visdata$civ.light)
testchi <- chisq.test(chitable)
testchi
testchi$p.value
```

The Anova test on results in a p-value of `r anovasummary[[1]][["Pr(>F)"]][[1]]`.
The chi-square test reveals a p-value of `r testchi$p.value`. 

We will build a logistic regression using civil twilight and visibility as predictors for severity. We are predicting a categorical variable with more than two levels so an ordinal logistic regression can be used.

```{r results='markup'}
loadPkg("MASS")

vislogit <- polr(Severity ~ vis+civ.light, data = visdata, Hess = "TRUE")
vislogit
summary(vislogit)
vistable <- coef(summary(vislogit))

coefs = exp(coef(vislogit))
xkabledply( as.table(coefs), title = "Exponentials of Coefficients for Model" )
#xkabledply(vislogit, title = paste("Logistic Regression :", format(formula(vislogit)) ))

vispredict = predict(vislogit, visdata)
table(visdata$Severity, vispredict)

loadPkg("pscl")
visaic <- AIC(vislogit)
visaic
vispr <- pR2(vislogit)
vispr

unloadPkg("pscl")
unloadPkg("MASS")

results <- coef(summary(vislogit))
p <- pnorm(abs(results[, "t value"]),lower.tail = FALSE)* 2
results <- cbind(results, "p-value" = round(p,3))
results
```

Results:

Every unit increase in miles of visibility decreases the odds-ratio by a factor of `r format(coefs[1],digit=4)`. The effect from the time being night (as per Civil Twilight) hurts the odds-ratio by a factor of `r format(coefs[2],digit=4)`.

We can add another variable to the model to see if there are any improvements and we can choose pressure because we know it has an impact on severity. 

```{r}
loadPkg("MASS")

vislogit2 <- polr(Severity ~ vis+civ.light+Pressure.in., data = visdata, Hess = "TRUE")
vislogit2
summary(vislogit2)
vistable2 <- coef(summary(vislogit2))

coefs2 = exp(coef(vislogit2))
xkabledply( as.table(coefs2), title = "Exponentials of Coefficients for Model" )

vispredict2 = predict(vislogit2, visdata)
table(visdata$Severity, vispredict2)

loadPkg("pscl")
visaic2 <- AIC(vislogit)
visaic2
vispr2 <- pR2(vislogit)
vispr2

unloadPkg("pscl")
unloadPkg("MASS")

results2 <- coef(summary(vislogit2))
p <- pnorm(abs(results[, "t value"]),lower.tail = FALSE)* 2
results <- cbind(results2, "p-value" = round(p,3))
results2
```

Building a second model with `Pressure.in.` as an additional predictor does not do much to improve the model. The McFadden test shows very minor improvement while AIC is worse off and the correlation matrix shows no improvement.

### Is there any relationship between the severity of an accident and the road conditions (traffic stops, railways, junctions, etc.)?

Preprocessing and cleaning

First of all, we tailored the dataset so we could keep the data that we needed. We then converted some columns into factors as needed.
```{r}
df=subset(dataset,select=c(Severity, Amenity,Bump, Crossing,Give_Way, Junction, No_Exit, Railway, Roundabout,Station, Stop, Traffic_Calming, Traffic_Signal, Turning_Loop))
str(df)
df=as.data.frame(df)
df$Amenity = factor(df$Amenity)
df$Bump=factor(df$Bump)
df$Crossing=factor(df$Crossing)
df$Give_Way=factor(df$Give_Way)
df$Junction=factor(df$Junction)
df$No_Exit=factor(df$No_Exit)
df$Railway=factor(df$Railway)
df$Roundabout=factor(df$Roundabout)
df$Station=factor(df$Station)
df$Stop=factor(df$Stop)
df$Traffic_Calming=factor(df$Traffic_Calming)
df$Traffic_Signal=factor(df$Traffic_Signal)
df$Turning_Loop=factor(df$Turning_Loop)
df$Severity=as.factor(df$Severity)
head(df)
```
Note: After reviewing the structure of the data set, we found out that "Turning_Loop" only had one level, meaning that the values of it were all "False".Therefore, we excluded it from our analysis for now. 


Analysis - Logistic Regression

```{r}
set.seed(100)
trainingRows <- sample(1:nrow(df), 0.7 * nrow(df))
trainingData <- df[trainingRows, ]
testData <- df[-trainingRows, ]
loadPkg("MASS")
dfLogit <- polr(Severity ~ Amenity+Bump+Crossing+Give_Way+Junction+No_Exit+Railway+Roundabout+Station+Stop+Traffic_Calming+Traffic_Signal, data = df, Hess = "TRUE")
dfLogit
summary(dfLogit)
(ctable <- coef(summary(dfLogit)))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))
xkabledply( confint.default(dfLogit), title = "CIs using standard errors" )
expcoeff = exp(coef(dfLogit))
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
```
Interpretation: 

According to the exponential of coefficients table, all the coefficient were significant (P-values greater than 0.05).

According to the confidence interval table, if the 95% CI did not cross 0, the parameter estimate could be statistically significant, therefore, "Bump", "Crossing","No-Exit","Stop",'Traffic_Signal", "Roundabout", and "Station" were not statistically significant.

When there was an amenity, the odds of the accident being more severe (i.e.,4, 3,2 versus 1) was 1.295 times that of the accidents which had no amenity, holding constant all other variables.

When there was a give-way, the odds of the accident being more severe (i.e.,4, 3,2 versus 1) was 1.913 times that of the accidents which had no give-way, holding constant all other variables.

When there was a junction, the odds of the accident being more severe (i.e.,4, 3,2 versus 1) was 1.213 times that of the accidents which had no junction, holding constant all other variables.

When there was railway, the odds of the accident being more severe (i.e.,4, 3,2 versus 1) was 1.393 times that of the accidents which had no railway, holding constant all other variables.

When there was traffic-calming, the odds of the accident being more severe (i.e.,4, 3,2 versus 1) was 2.855 times that of the accidents which had no traffic-traffic-calming, holding constant all other variables.


Two-way contingency table of the outcome and predictors

```{r}
table = xtabs(~ Severity + Amenity+Give_Way+Junction+Railway+Traffic_Calming, data = df)
table
```
Interpretation - Two-way contingency table

From the results generated by the two-way contingency table, we can see that, when there was an amenity, and no other predictor variables in place, there was 8766 accidents that had a severity level of "2", 1087 accidents that had a severity level of "4", 1011 accidents that had a severity level of "3", and 413 accidents that had a severity level of "1"

We can also see that many of the accidents happened when the following road conditions were present: "Crossing", "Give-Way", "Junction","Traffic_Calming,"Railway", and "Amenity".

This result, although preliminary, showed us that these road conditions, especially "Amenity", may have affected the severity of the accident.

Ordinal Logistic Regression - Model Evaluation

```{r}
summary(dfLogit)
```
The residual deviance showed how well the response was predicted by the model when the predictor variables were included. From the results, we saw that the residual deviance went up by 2069521.55 when the predictor variables were added, this increase in deviance was evidence of a significant lack of fit.

McFadden Statistics

```{r}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
admitLogitpr2 = pR2(dfLogit)
admitLogitpr2
unloadPkg("pscl") 
```
According to the McFadden statistics, only 1.36% of the variations in y is explained by the explanatory variables in the model. This result urged us to look at other variables in the dataset that may explain the severity the accident.


## Findings

We were able to construct a Random Forest classifier model to predict the severity of an accident using the predictor variables in the data set related to weather conditions. The first model we constructed, which serves as the null model, performed poorly due to the class imbalance in the data. Because the overwhelming majority of observations are of severity '2', the model is rewarded for naively predicting severity '2' with little regard for precision. The model resulted in a class error of $57.68\%$ for severity '1', $70.49\%$ for severity '3', and $67.23\%$ for severity '4'. We were able to improve upon this null model by implementing stratified sampling in our second Random Forests model. We observed a drastic reduction in class error for severity '1', '3', and '4'. The model resulted in a class error of $38.4\%$ for severity '1', $49\%$ for severity '3', and $61.4\%$ for severity '4'. While the class error is still relatively high for this second model, it is a drastic improvement over the null model.

By constructing a Random Forest classifier model with all relevant features in the data set, we were able to examine which variables hold the most predictive value in classifying the severity of an accident. We saw that Atmospheric Pressure had the biggest impact on Mean Decrease in Accuracy and Gini when omitted from the model. High atmospheric pressure readings indicate fair, calm weather, while low-pressure weather systems bring cloudiness, high winds, and precipitation (National Geographic). The classifier model we constructed relied on Atmospheric Pressure more than any other predictor variable because of its far-reaching impact on weather conditions. All of the symptoms of low pressure weather systems make driving more difficult, leading to more severe accidents.

The results of the ANOVA and Chi-squared tests showed very small p-values so we know that these are statistically significant relationships but still civil twilight and visibility are most likely not enough to predict severity. The logistic regression is good at predicting accidents with level two severity likely because that is the severity level that the data favors. A correlation matrix for the model reveals that the model miss-classifies roughly 14% of accidents. Overall this model is not a good fit with a very high AIC and low McFadden. An attempt to improve the model does very little and is still not a good fit. 

In terms of exploring the relationship between the severity of the accident and the road conditions, the two-way contingency table did show that "Amenity", "Crossing", "Junction", and "Give-way" affected the severity of the accident. Among these conditions, "Amenity" stood out.The ordinal regression model also showed that with these road conditions made the severity level higher, however, after evaluating the logistic regression model, the model was considered as significantly ineffective in predicting the level of severity. 


# Conclusion

Common knowledge tells us that poor weather conditions cause more severe traffic accidents. We were able to confirm this using modeling techniques. We were able to predict the severity of an accident using various predictor variables related to weather conditions at the time of the accident, with a fair degree of accuracy. Random Forest modeling tells us that Atmospheric Pressure best predicts the severity of an accident because of its effects on visibility, precipitation, and wind.

Severity is related to both visibility and civil twilight however these variables do not make a good fit as predictors for severity. Adding another variable to the regression did not improve the results but attempting to weight the data so that it is not skewed to favor level two severity accidents may help to improve the model.

The ordinal logistic regression model being ineffective in predicting the severity of the accident may be due to unbalanced data. As we saw, most of the accidents had a severity level of "2". To better explore the relationship between the severity of the accident and road conditions, may be we can try using a different data analyzing method relying on the results generated by the two-way contingency table.

# References

National Geographic Society. “Atmospheric Pressure.” National Geographic Society, 9 Oct. 2012, https://www.nationalgeographic.org/encyclopedia/atmospheric-pressure/. 
