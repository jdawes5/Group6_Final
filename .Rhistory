biplot(pr.cars.nc,2:3, scale =0)
biplot(pr.cars,3:4, scale =0)
biplot(pr.cars.nc,3:4, scale =0)
#We can also use ggplot to vis the output
# install.packages("devtools")
# loadPkg("devtools")
# install_github("ggbiplot", "vqv")
# loadPkg("ggbiplot")
# g <- ggbiplot(pr.out,2:3, obs.scale = 1, var.scale = 1, ellipse = TRUE,circle = TRUE)
# print(g)
loadPkg("pls")
loadPkg("mice")
loadPkg("ISLR")
#Again we want to scale our data and "CV" stands for cross validation, which is defaulted to RMSE, using Hitters Data Set in the ISLR package
Hitters2 <- Hitters[,c("Salary","AtBat","Hits","HmRun","Runs","RBI","Walks","Assists","Errors")]
pcr.fit=pcr(Salary~.,data=Hitters2,scale=TRUE,validation ="CV")
xkabledplyhead(Hitters2)
summary(pcr.fit)
# xkabledply(pcr.fit) # doesn't work for this special pcr model object!
pcr.fit$coefficients[1:8,1,'1 comps'] # only one coefficient for PC1, but expressed in the original variables coefficients.
pcr.fit$coefficients[1:8,1,'3 comps'] # three coefficients for PC1, PC2, and PC3, but expressed in the original variables coefficients.
#
pcr.fit$fitted.values[1:5,1,'1 comps'] # the fitted values. Showing only the first five here.
pcr.fit$fitted.values[1:5,1,'3 comps']
Hitters2scaled.pc <- PCAxform( Hitters2[,2:9], z=TRUE ) # exclude salary column at index 1
Hitters2scaled.pc$Salary = Hitters2[,1] # copy back the salary as y-target
cor(Hitters2scaled.pc)
cov(Hitters2scaled.pc)
loadPkg("faraway")
# Using PC
vif.pc = lm(Salary~., data=Hitters2scaled.pc)
vif(vif.pc)
xkablevif(vif.pc, title = "VIFs for model using PCA")
xkabledply(vif.pc, title = "Model summary for model using PCA")
# Using original, scaled df
vif.lms = lm(Salary~., data=Hitters2scaled)
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
loadPkg("FNN")
#For this example we are going to use the IRIS dataset in R
str(iris)
loadPkg('ggplot2')
#plot(iris[,1],iris[,2], col=iris$Species)
for (xx in 1:(length(iris)-2) ) {
for (yy in (xx+1):(length(iris)-1) ) {
print(xx)
print(yy)
p <- ggplot(iris, aes(x=iris[,xx], y=iris[,yy], color=Species)) +
geom_point() +
scale_color_manual(values = c("setosa" = "purple", "versicolor"="orange","virginica"="steelblue")) +
labs( x = colnames(iris)[xx], y = colnames(iris)[yy], title = paste(colnames(iris)[yy],"vs",colnames(iris)[xx]) )
print(p)
}
}
# xx <- 1
# yy <- 2
# ggplot(iris, aes(x=iris[,xx], y=iris[,yy], color=Species)) +
#   geom_point() +
#   scale_color_manual(values = c("setosa" = "purple", "versicolor"="orange","virginica"="steelblue")) +
#   labs( x = colnames(iris)[xx], y = colnames(iris)[yy], title = paste(colnames(iris)[yy],"vs",colnames(iris)[xx]) )
#first we want to scale the data so KNN will operate correctly
scalediris <- as.data.frame(scale(iris[1:4], center = TRUE, scale = TRUE))
#We also need to create test and train data sets, we will do this slightly differently by using the sample function. The 2 says create 2 data sets essentially, replacement means we can reset the random sampling across each vector and the probability gives sample the weight of the splits, 2/3 for train, 1/3 for test.
set.seed(1000)
iris_sample <- sample(2, nrow(scalediris), replace=TRUE, prob=c(0.67, 0.33))
#We then just need to use the new variable to create the test/train outputs, selecting the first four rows as they are the numeric data in the iris data set and we want to predict Species
iris_training <- scalediris[iris_sample==1, 1:4]
iris_test <- scalediris[iris_sample==2, 1:4]
#Now we need to create our 'Y' variables or labels need to input into the KNN function
iris.trainLabels <- iris[iris_sample==1, 5]
iris.testLabels <- iris[iris_sample==2, 5]
#So now we will deploy our model
iris_pred <- knn(train = iris_training, test = iris_test, cl=iris.trainLabels, k=7)
# iris_pred
loadPkg("gmodels")
IRISPREDCross <- CrossTable(iris.testLabels, iris_pred, prop.chisq = FALSE)
#Looks like we got all but three correct, not bad
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret") # confusionMatrix
# Loop thru different k values
# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
for (kval in 3:11) {
iris_pred <- knn(train = iris_training, test = iris_test, cl=iris.trainLabels, k=kval)
IRISPREDCross <- CrossTable(iris.testLabels, iris_pred, prop.chisq = FALSE)
print( paste("k = ", kval) )
IRISPREDCross
#
cm = confusionMatrix(iris_pred, reference = iris.testLabels ) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
xkabledply(ResultDf, "Total Accuracy Summary")
bank_data = read.csv("bank.csv",                #<- name of the data set.
check.names = FALSE,       #<- don't change column names.
stringsAsFactors = FALSE)  #<- don't convert the numbers and characters to factors.
# Check the structure and view the data.
str(bank_data)
xkabledplyhead(bank_data)
xkabledplytail(bank_data)
# Let's run the kNN algorithm on our banking data.
# Check the composition of labels in the data set.
table(bank_data$`signed up`)
table(bank_data$`signed up`)[2] / sum(table(bank_data$`signed up`))
# This means that at random, we have an 11.6% chance of correctly picking
# out a subscribed individual. Let's see if kNN can do any better.
# Let's split the data into a training and a test set.
# Sample 80% of our know data as training and 20% as test.
set.seed(1)
bank_data_train_rows = sample(1:nrow(bank_data),     #<- from 1 to the number of rows in the data set
round(0.8 * nrow(bank_data), 0),  #<- multiply the number of rows by 0.8 and round the decimals
replace = FALSE)       #<- don't replace the numbers
# Let's check to make sure we have 80% of the rows.
length(bank_data_train_rows) / nrow(bank_data)
bank_data_train = bank_data[bank_data_train_rows, ]  #<- select the rows identified in the bank_data_train_rows data
bank_data_test = bank_data[-bank_data_train_rows, ]  #<- select the rows that weren't identified in the bank_data_train_rows data
# Check the number of rows in each set.
nrow(bank_data_train)
nrow(bank_data_test)
# Let's train the classifier for k = 3.
# Install the "class" package that we'll use to run kNN.
# Take some time to learn about all its functionality.
# install.packages("class")
loadPkg("class")
# k-Nearest Neighbor is a randomized algorithm, so make sure to
# use set.seed() to make your results repeatable.
set.seed(1)
bank_3NN = knn(train = bank_data_train[, c("age", "balance", "duration")],  #<- training set cases
test = bank_data_test[, c("age", "balance", "duration")],    #<- test set cases
cl = bank_data_train[, "signed up"],                         #<- category for true classification
k = 3) #,                                                    #<- number of neighbors considered
# use.all = TRUE)                                            #<- control ties between class assignments
#   If true, all distances equal to the k-th largest are included
# View the output.
str(bank_3NN)
length(bank_3NN)
table(bank_3NN)
# How does the kNN classification compare to the true class?
# Let's take a look at the confusion matrix by combining the
# predictions from bank_3NN to the original data set.
kNN_res = table(bank_3NN,
bank_data_test$`signed up`)
kNN_res
sum(kNN_res)  #<- the total is all the test examples
# Select the true positives and true negatives by selecting
# only the cells where the row and column names are the same.
kNN_res[row(kNN_res) == col(kNN_res)]
# Calculate the accuracy rate by dividing the correct classifications
# by the total number of classifications.
kNN_acc = sum(kNN_res[row(kNN_res) == col(kNN_res)]) / sum(kNN_res)
kNN_acc
loadPkg("caret")
cm = confusionMatrix(bank_3NN, reference = as.factor(bank_data_test[, "signed up"]) )
cm$overall
cm$byClass
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
set.seed(1)
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k) #,                #<- number of neighbors considered
# use.all = TRUE)       #<- control ties between class assignments. If true, all distances equal to the k-th largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
# The sapply() function plugs in several values into our chooseK function.
# function(x)[function] allows you to apply a series of numbers
# to a function without running a for() loop.
knn_different_k = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = bank_data_train[, c("age", "balance", "duration")],
val_set = bank_data_test[, c("age", "balance", "duration")],
train_class = bank_data_train[, "signed up"],
val_class = bank_data_test[, "signed up"]))
# Reformat the results to graph the results.
str(knn_different_k)
knn_different_k = data.frame(k = knn_different_k[1,],
accuracy = knn_different_k[2,])
# Plot accuracy vs. k.
# install.packages("ggplot2")
loadPkg("ggplot2")
ggplot(knn_different_k,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3) +
labs(title = "accuracy vs k")
v1=c(2,3,4,10,11,12,20,25,30) # use the example in the pptx, try k=2 clusters
for( cut in 2:(length(v1)-2) ) {
print(
paste(
"mean 1 = ",mean(v1[1:cut]),
"mean 2 = ", mean(v1[(cut+1):length(v1)]),
"Sum of Sqaures  = ", (cut-1)*var(v1[1:cut]) + (length(v1)-cut-1)*var(v1[(cut+1):length(v1)]),
"cluster 1 len = ", cut, "cluster 2 len = ", (length(v1) - cut)
)
)
}
v1clusters <- kmeans(v1,3)
v1clusters
v2 <- NULL
v2 <- as.data.frame(v1)
colnames(v2) <- c("var1")
v2$var2 <- c(30,21,26,15,8,11,5,9,6)
plot(v2[,1:2], main = "K-means, var2 vs var1")
v2
v2clusters3 <- kmeans(v2,3)
v2clusters3
v2$label = v2clusters3$cluster
xkabledplyhead(v2, rows = 2)
xkabledplytail(v2, rows = 2)
plot(v2$var1,v2$var2, col=v2$label, main = "3 clusters: var2 vs var1", xlab = "var1", ylab = "var2")
ggplot(v2, aes(x=var1, y=var2, color= factor(label) )) + geom_point() + labs( title = "3 clusters: var2 vs var1", color="Cluster" )
v2clusters2 <- kmeans(v2,2)
#v2clusters2
v2$label = v2clusters2$cluster
xkabledplyhead(v2, rows = 2)
xkabledplytail(v2, rows = 2)
plot(v2$var1,v2$var2, col=v2$label, main = "2 clusters: var2 vs var1", xlab = "var1", ylab = "var2")
ggplot(v2, aes(x=var1, y=var2, color= factor(label) )) + geom_point() + labs( title = "2 clusters: var2 vs var1", color="Cluster" )
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- httr::GET("https://www.kaggle.com/sobhanmoosavi/us-accidents/download",
httr::authenticate(username, authkey, type = "basic"))
dataset <- httr::GET("https://www.kaggle.com/sobhanmoosavi/us-accidents/download",
httr::authenticate(crogers21, Harper@3417, type = "basic"))
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
install.packages(c("devtools"))
devtools::install_github("ldurazo/kaggler")
install.packages(c("devtools"))
install.packages(c("devtools"))
install.packages(c("devtools"))
install.packages(c("devtools"))
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library(readr)
library(kaggler)
install.packages("kaggler")
install.packages(c("devtools"))
devtools::install_github("ldurazo/kaggler")
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
View(dataset)
#dataset <- read.csv("US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset)
str(dataset)
#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)
str(dataset)
#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp))
View(dataset)
#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset) #335,552 observations remaining
#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)
#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))
table(dataset$Severity)
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State)
#ggplot(data = dataset, aes(x = ))
str(dataset)
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot()
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot() #looks wacky with most distances = 0
ggplot(data = dataset, aes(x = Distance.mi.)) + geom_histogram()
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot() #looks wacky with most distances = 0
ggplot(data = dataset, aes(x = Distance.mi.)) + geom_histogram(binwidth = .05)
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot() #looks wacky with most distances = 0
ggplot(data = dataset, aes(x = Distance.mi.)) + geom_histogram(binwidth = .05) + scale_x_continuous(limits = c(0, 10))
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3, scipen = 999)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3, scipen = 999)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset) #335,552 observations remaining
#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)
#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot() #looks wacky with most distances = 0
ggplot(data = dataset, aes(x = Distance.mi.)) + geom_histogram(binwidth = .05) + scale_x_continuous(limits = c(0, 10))
getwd()
setwd("~/Group6_Final")
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(ezids)
library(httr)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3, scipen = 999)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
dataset <- read.csv("US_Accidents_Dec20_updated.csv")
dataset <- na.omit(dataset) #335,552 observations remaining
#encoding correct datatypes
dataset$ID <- as.character(dataset$ID)
dataset$Severity <- as.factor(dataset$Severity)
dataset$Start_Time <- as.character(dataset$Start_Time)
dataset$End_Time <- as.character(dataset$End_Time)
dataset$Description <- as.character(dataset$Description)
dataset$Street <- as.character(dataset$Street)
dataset$City <- as.character(dataset$City)
dataset$County <- as.character(dataset$County)
dataset$State <- as.character(dataset$State)
dataset$Zipcode <- as.numeric(dataset$Zipcode)
dataset$Airport_Code <- as.character(dataset$Airport_Code)
dataset$Weather_Timestamp <- as.character(dataset$Weather_Timestamp)
dataset$Weather_Condition <- as.character(dataset$Weather_Condition)
#remove unnecessary columns
dataset <- subset(dataset, select = -c(Number, Street, Side, Airport_Code, Weather_Timestamp, Start_Lat, Start_Lng, End_Lat, End_Lng))
table(dataset$Severity) #vast majority are severity 2, why?
table(dataset$State) #states w/large pop have most accidents, no surprises there
ggplot(data = dataset, aes(x = Severity, y = Distance.mi.)) + geom_boxplot() #looks wacky with most distances = 0
ggplot(data = dataset, aes(x = Distance.mi.)) + geom_histogram(binwidth = .05) + scale_x_continuous(limits = c(0, 10)) #may need to omit distances of 0
